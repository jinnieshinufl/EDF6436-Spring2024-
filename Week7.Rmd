---
title: "Validity"
author: "Jinnie shin | jinnie.shin@coe.ufl.edu"
output: html_notebook
---

```{r setup, include=FALSE}
#install.packages(c( 'stringr','Hmisc', 'reshape2', 'surveydata', 'dplyr'))
library(truncnorm)
library(ggplot2)
library(stringr)
library(Hmisc)
library(reshape2)
library(surveydata)
library(dplyr)
knitr::opts_chunk$set(echo = FALSE)
```

## 1. Data
### `interest` data 

```{r, result1}
urlfile="https://raw.githubusercontent.com/jinnieshinufl/EDF6436-Spring2024-/main/interest.csv"
data<-read_csv(url(urlfile), col_names=TRUE) 
interest<- as.data.frame(data)


complement <- function(y, rho, x) {
  if (missing(x)) x <- rnorm(length(y)) # Optional: supply a default if `x` is not given
  y.perp <- residuals(lm(x ~ y))
  rho * sd(y.perp) * y + y.perp * sd(y) * sqrt(1 - rho^2)
}

my.data <- data.frame(stress.self = interest$stress,
                      impulsve.self = interest$impulsve, 
                      worry.self = interest$worry)
my.data$'stress.peer' = round(complement(my.data$stress.self, 0.752),2)
my.data$'impulsve.peer' = round(complement(my.data$impulsve.self, 0.89),2)
my.data$'worry.peer' = round(complement(my.data$worry.self, 0.783),2)

```

```{r}
head(interest)
```

### Let's check the dimension 
```{r, q23, exercise=TRUE}
# column names? 



```

### Descriptive Statistics 
```{r, q24, exercise=TRUE}


```

### Test Score Histogram - `reading`, `sentcomp`, `mathmtcs`

```{r, q25, exercise=TRUE}


```

## 2. Content Validity 

A common form of validity evidence is expert opinion. The opinions of experts can help comment on the appropriateness of the content of the items, whether the instrument is adequately sampling all the concepts within the construct, and whether the items are essential for measuring the target construct. One way to quantify the latter is with the content validity ratio, CVR (Lawshe, 1975). The CVR is defined as:

$$ CVR = \frac{n_{e}-(N/2)}{N/2} $$ 

- $n_{e}$ represent the number of experts who deem the item as essential and $N$ is the total number of experts.

- If we ask 20 experts if they think this item is
essential to measuring aggression in children and 17 agree it is, then the CVR can be calculated as: 

```{r, q1, exercise=TRUE}


```

## 3. Criterion-referenced Validity 

we would expect that the vocabulary test (vocab) would be correlated with assessments that measure reading comprehension (reading) and sentence completion (sentcomp). Thus, we can use the `cor` function to calculate the Pearson correlation between these variables

```{r, cor, exercise=TRUE, ech=FALSE}
cor(interest[, c("vocab", "reading", "sentcomp")])

```

```{r a, echo=FALSE}
question("If the vocabulary tests were administered at the time of the reading and sentence completion assessments, This is the evidence of",
  answer("Concurrent validity"),
  answer("Predictive validity")
)
```

Assume that we are measuring studentâ€™s interest in becoming a teacher
(`teacher`) after graduation using a personality measure of social dominance (`socdom`), which they completed in their first year. 

```{r b, exercise=TRUE, echo=FALSE}
mod <- lm(teacher ~ socdom, interest)

summary(mod)
```

```{r c, echo=FALSE}
question("The findings could be used as evidence of ________ validity of the social dominance assessment scores",
  answer("Concurrent validity"),
  answer("Predictive validity", correct = TRUE)
)
```

## 4. MTMM

```{r}
head(interest)
```


```{r, mtmm, exercise=TRUE, echo=FALSE}
## function for rendering a multi trait multi method matrix
mtmm = function (
    variables, # data frame of variables that are supposed to be correlated
    reliabilities = NULL, # reliabilties: column 1: scale, column 2: rel. coefficient
    split_regex = "\\.", # regular expression to separate construct and method from the variable name. the first two matched groups are chosen
    cors = NULL
) {

    if(is.null(cors)) 
        cors = cor(variables, use="pairwise.complete.obs") # select variables

    var.names = colnames(cors)

    corm = melt(cors)
    corm = corm[ corm[,'Var1']!=corm[,'Var2'] , ] # substitute the 1s with the scale reliabilities here
    if(!is.null(reliabilities)) {
        rel = reliabilities
        names(rel) = c('Var1','value')
        rel$Var2 = rel$Var1
        rel = rel[which(rel$Var1 %in% var.names), c('Var1','Var2','value')]
        corm = rbind(corm,rel)
    }

    if(any(is.na(str_split_fixed(corm$Var1,split_regex,n = 2)))) 
	{
		print(unique(str_split_fixed(corm$Var1,split_regex,n = 2)))
		stop ("regex broken")
	}
	corm[, c('trait_X','method_X')] = str_split_fixed(corm$Var1,split_regex,n = 2)  # regex matching our column naming schema to extract trait and method
    corm[, c('trait_Y','method_Y')] = str_split_fixed(corm$Var2,split_regex,n = 2)

    corm[,c('var1.s','var2.s')] <- t(apply(corm[,c('Var1','Var2')], 1, sort)) # sort pairs to find dupes
    corm[which(
        corm[ ,'trait_X']==corm[,'trait_Y'] 
        & corm[,'method_X']!=corm[,'method_Y']),'type'] = '(A)'
    corm[which(
        corm[ ,'trait_X']!=corm[,'trait_Y'] 
        & corm[,'method_X']==corm[,'method_Y']), 'type'] = '(B)'
    corm[which(
        corm[ ,'trait_X']!=corm[,'trait_Y'] 
        & corm[,'method_X']!=corm[,'method_Y']), 'type'] ='(C)'
    corm[which( 
        corm[, 'trait_X']==corm[,'trait_Y'] 
        & corm[,'method_X']==corm[,'method_Y']), 'type'] ='(D)'

    corm$trait_X = factor(corm$trait_X)
    corm$trait_Y = factor(corm$trait_Y,levels=rev(levels(corm$trait_X)))
	corm$method_X = factor(corm$method_X)
	corm$method_Y = factor(corm$method_Y,levels=levels(corm$method_X))
    corm = corm[order(corm$method_X,corm$trait_X),]
    corm = corm[!duplicated(corm[,c('var1.s','var2.s')]), ] # remove dupe pairs

    #building ggplot
    mtmm_plot <- ggplot(data= corm) + # the melted correlation matrix
        geom_tile(aes(x = trait_X, y = trait_Y, fill = type)) + 
        geom_text(aes(x = trait_X, y = trait_Y, label = str_replace(round(value,2),"0\\.", ".") ,size=log(value^2))) + # the correlation text
        facet_grid(method_Y ~ method_X) + 
        ylab("")+ xlab("")+
        theme_bw(base_size = 18) + 
        theme(panel.background = element_rect(colour = NA), 
                    panel.grid.minor = element_blank(), 
                    axis.line = element_line(), 
                    strip.background = element_blank(),
                    panel.grid = element_blank(),
                    legend.position = c(1,1),
                    legend.justification = c(1, 1)
        ) + 
        scale_fill_brewer('Type') +
        scale_size("Absolute size",guide='none') +
        scale_colour_gradient(guide='none')

    mtmm_plot
}

data.mtmm = my.data
reliabilities = data.frame(scale = names(data.mtmm), rel = c(0.89, 0.87, 0.65, 0.97, 0.88, 0.79))
mtmm(data.mtmm, reliabilities = reliabilities)
```

```{r q3, echo=FALSE}
question("Which of the following component identify the reliability of the scales",
  answer("(A)"),
  answer("(B)"),
  answer("(C)"),
  answer("(D)")
)
```


## 5. Survey data analysis 

### 1. Data - member satisfaction survey, `survey`.

```{r data2, exercise=TRUE, exercise.lines=10}
# 1. Attach the two libraries  'surveydata', 'dplyr'



# 2. data 

survey <- membersurvey %>% as.tbl()
```

### 2. Descriptive analysis 

```{r data3, exercise=TRUE, exercise.lines=5, exercise.setup="data2"}
# 3. Descriptive analysis 
### overview the data 


```

```{r data4, exercise=TRUE, exercise.lines=5, exercise.setup="data2"}
# 4. Descriptive statistics 
### overview the data 


```

### 3. Subselecting the data and recoding 

```{r data5, exercise=TRUE, exercise.lines=12, exercise.setup="data2"}
### select the columns with the binary responses yes/no (Q3_1 ~ Q3_15)

### Let's call the subselected data => survey_short
survey_short = survey[, 5:19]

### recoding the data 



```

### 4. Item Analysis 

```{r data6, exercise=TRUE, exercise.lines=15, exercise.setup="data5"}
### item mean 





### item variance 




### Total Score 



```

```{r data7, exercise=TRUE, exercise.lines=15, exercise.setup="data5"}
### Internal consistency 







```

