---
title: "Confirmatory Factor Analysis"
author: "Jinnie shin | jinnie.shin@coe.ufl.edu"
date: "26/3/2024"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(lavaan)
library(learnr)
library(corrplot)
library(semTools)
```

## 1. Data 
We will use the `lavaan` package (Rosseel et al., 2020) for estimating confirmatory factor analysis models. 

- We will use the Holzinger and Swineford Dataset, which you can read more about with `?HolzingerSwineford1939`

```{r print-limit-hint}
data(HolzingerSwineford1939)
dat <- HolzingerSwineford1939[,7:15] # we will simply call this data `dat`
```

The hypothesized factor structure is as follows: 

- A visual factor measured by: `x1 (Visual perception)`, `x2 (Cubes)`, and 
`x3 (Lozenges)` 

- A textual factor measured by: `x4 (Paragraph comprehension)`, `x5 (Sentence completion)`, and `x6 (Word meaning)` 

- A speed factor measured by: `x7 (Speeded addition)`,  `x8 (Speeded counting of dots)`, and `x9 (Speeded discrimination straight and curved capitals)` 

## 2. Assumption checking 
### Normality of Variable 
For multivariate normality, We can use the `mardiaKurtosis()` function from the `semTools` package. We can check multivariate skewness and kurtosis (Mardia’s coefficients):

```{r, ass1, exercise=TRUE, echo=TRUE }
library(semTools)
multi_out <- mardiaKurtosis(dat, use = "everything")
round(multi_out,3)

multi_out2 <- mardiaSkew(dat, use = "everything")
round(multi_out2,3)
```

```{text}
Both skewness and kurtosis are very high, pointing to multivariate outliers that might inflate 
standard errors of coefficients (coefficients themselves are mostly unaffected by non-normality).
```

#### EXERCISE 
```{r question, echo=FALSE}
question("which of the following statement is true? (Select all)",
         answer("The violation informs our estimation model selection"), 
         answer("We might need to remove the outliers "),
         answer("The violation is minimal so we can proceed as is"),
         answer("We should report this result as it has implciations on the confidence in interperting the results")
)
```

## 3. Case 1 - CFA specificaiton
Instead of using maximum likelihood estimation, we can use a robust estimation approach, specifically the “maximum likelihood robust” (MLR) method. 
- Adjustment: Chi-squared (and associated fit statistics that use it: RMSEA, CFI, TLI)

We will first specify the model using the `lavaan` package.

- `=~` is used for factor loadings (e.g.,`VISUAL =~ x1`)
- `~~` is used for variance and covariances (e.g., `VISUAL ~~ VISUAL`)
- `*` is used to fix a parameter to a specific value (e.g., `VISUAL ~~ 1*VISUAL`)

```{r, case1, echo=FALSE, exercise=TRUE}
library(lavaan)

model <- "VISUAL =~ x1 + x2 + x3 
          TEXUAL =~ x4 + x5 + x6 
          SPEED  =~ x7 + x8 + x9
          "
``` 

Once we specified and saved our model to `model`, we can fit the model using the `cfa()` function. We will use the `estimator="MLR"`to specify the robust maximum likelihood estimation method. We can use the `mimic = "Mplus"` argument if we wish to acquire output that is similar to what it would be if we were to use Mplus software.

```{r, cfa1, exercise=TRUE, echo=FALSE, exercise.setup= 'case1'}

cfa_fit1 <- cfa(model, 
                data = dat,
                estimator = "MLR", 
                mimic = "Mplus")

``` 

Let's take a look at the model fit together

```{r cfa1-result, exercise=TRUE, echo=FALSE, exercise.setup= 'cfa1'}
summary(cfa_fit1, 
        fit.measures = TRUE, 
        standardized = TRUE, 
        rsquare      = TRUE)
```
## 4. Case 1 - Model Evaluation 
### Model fit indices 

- Each fit index answers a different question about model fit \ 
- CFI/TLI, SRMR, RMSEA, Chi-square ....

#### Explanations
- **Chi-squared**: Assess the overall fit and the discrepancy between the sample and fitted covariance matrices. Its p-value should be > .05 (i.e., the hypothesis of a perfect fit cannot be rejected). However, it is quite sensitive to sample size.

- **CFI**: The Comparative Fit Index is a revised form of NFI. Not very sensitive to sample size (Fan, Thompson, & Wang, 1999). Compares the fit of a target model to the fit of an independent, or null, model. It should be > .90.

- **RMSEA** : The Root Mean Square Error of Approximation is a parsimony-adjusted index. Values closer to 0 represent a good fit. It should be < .08 or < .05. The p-value printed with it tests the hypothesis that RMSEA is less than or equal to .05 (a cutoff sometimes used for good fit), and thus should be not significant.

- **SRMR**: the (Standardized) Root Mean Square Residual represents the square-root of the difference between the residuals of the sample covariance matrix and the hypothesized model. As the RMR can be sometimes hard to interpret, better to use SRMR. Should be < .08.

```{r, cfa1-fit, exercise=TRUE, echo=TRUE, exercise.setup= 'cfa1'}
fit_stats <- fitMeasures(cfa_fit1, c("chisq.scaled","df.scaled", "pvalue.scaled", 
                                    "cfi.robust", 
                                    "tli.robust", 
                                    "rmsea.robust", 
                                    "srmr"))
fit_stats
``` 


### Path Digrams 
```{r, cfa1-plot, exercise=TRUE, echo=FALSE, exercise.setup= 'cfa1'}
library(semPlot)
semPlot::semPaths(cfa_fit1, what = "est", intercept = FALSE,
                  rotation = 2, fade = F, edge.color = "black", 
                  curvePivot = T, sizeMan = 8, residuals = F, curvature = 2.5,
                  title = FALSE, sizeMan2 = 3, sizeLat2 = 8,
                  label.cex = 1, edge.label.cex = 1.2)

title("CFA Model 1", line = 1)
```
---

### Modification Indices 
  
  
```{r, modin1, exercise=TRUE, echo=FALSE, exercise.setup= 'cfa1'}
Mod_inds <- modindices(cfa_fit1, 
                       standardized  = TRUE,
                       minimum.value = 3.84,
                       sort. = TRUE)
Mod_inds[1:10, ]
```


#### Exercise: Modification Indices  
You can make changes in the model specification in order to accommodate the suggestions based on the modification indices 

```{r, exe, exercise=TRUE, echo=FALSE, exercise.lines=20}
# your code here 
new_model <-  # define your new model here 
  
  
cfa_fit1_new <- # fit the model 
```

#### Exercise:Model Comparisons
```{r compare, exercise=TRUE, echo=FALSE, exercise.setup= 'cfa1'}

anova(cfa_fit1, cfa_fit1_new)

``` 


### Insepct the Results
```{r inspect}
fitted(cfa_fit1_new)$cov # covariance structure estimated from your model (Estimated)
inspect(cfa_fit1_new, 'sampstat')$cov # sample covariance structure from your data (Real)

``` 


- How did the model fit change?
- Does this theoretically make sense? 
  
## 5. Case 1 - Standardized Solution 
  If we wish to set our factor scales to have a variance of 1 instead of forcing them to be on the scale of the first variable, we can use the `NA*` as a prefix to the first observed variable in a factor to tell lavaan to estimate that parameter. We then should set the variance of the factor to 1 using the `~~` operator with *1. Let's try this with the factor `VISUAL`

```{r cfa-sd, exercise=TRUE, echo=FALSE}

library(lavaan)
model2 <- "VISUAL =~ NA*x1 + x2 + x3 
          TEXTUAL =~ x4 + x5 + x6 
          SPEED  =~ x7 + x8 + x9
          
VISUAL ~~ 1*VISUAL"

cfa_fit2 <- cfa(model2, 
                data = dat,
           estimator = "MLR",
               mimic = "Mplus")

summary(cfa_fit2)
``` 

```{r cfa-sd-all, exercise=TRUE, echo=FALSE, exercise.setup='cfa-sd'}

cfa_fit_all <- cfa(model2, 
                data = dat,
           estimator = "MLR",
               mimic = "Mplus", 
           std.lv = TRUE)

summary(cfa_fit_all)
``` 


#### Plotting the diagram 
```{r, cfa-plot2, exercise=TRUE, echo=FALSE, exercise.setup='cfa-sd-all'}
semPlot::semPaths(cfa_fit_all, what = "est", intercept = F,
  rotation = 2, fade = F, edge.color = "black", 
  curvePivot = T, sizeMan = 8, residuals = F, curvature = 3,
  title = F, sizeMan2 = 3, sizeLat2 = 8,
  label.cex = 1, edge.label.cex = 1.2)

title("CFA Model 2: Factors Standardized solution", line = 1)
```

## 6. Case 2 - CFA specification 
Both skewness and kurtosis are very high, pointing to multivariate outliers that might inflate standard errors of coefficients (coefficients themselves are mostly unaffected by non-normality).

Thus, we remove all subjects/observations with values outside +/- 3 SD from the mean on at least one of the ten life satisfaction variables. By removing univariate outliers we also want to make sure that influential data points play no role for the factor solution.

### Remove the outliers 

```{r, new_cfa, exercise=TRUE, echo=FALSE}
library(tidyverse)

clean <- function(x) { 
(x >= mean(x) - 3*sd(x)) & (x <= mean(x) + 3*sd(x))  
}

clean_dat <- dat %>% 
  filter(clean(x1) & clean(x2) & clean(x3) & clean(x4) & clean(x5) &
          clean(x6) &clean(x7) &clean(x8) &clean(x9) )

```

### Check the normality assumption again 
```{r, normality, exercise=TRUE, echo=FALSE, exercise.setup="new_cfa"}
mardiaSkew(clean_dat, use = "everything")
mardiaKurtosis(clean_dat, use = "everything")
``` 

---

### Model Specification 

```{r cfa-case2, exercise=TRUE, echo=FALSE, exercise.setup="new_cfa"}

library(lavaan)
model3 <- "VISUAL =~ x1 + x2 + x3 
          TEXTUAL =~ x4 + x5 + x6 
          SPEED  =~ x7 + x8 + x9"

cfa_fit3 <- cfa(model3, 
                data = clean_dat,
               mimic = "Mplus")

summary(cfa_fit3)
``` 

```{r cfa-case3, exercise=TRUE, echo=FALSE, exercise.setup="new_cfa"}

library(lavaan)
model3 <- "VISUAL =~ x1 + x2 + x3 
          TEXTUAL =~ x4 + x5 + x6 
          SPEED  =~ x7 + x8 + x9"

cfa_fit4 <- cfa(model3, 
                data = clean_dat,
               mimic = "Mplus",
               std.lv = TRUE)

summary(cfa_fit4)
``` 

## 7. Case 3 - Categorical Data 
It is difficult to satisfy the normality assumption with categorical data. One approach to conducting CFA with categorical data is to use weighted-least-squares-means-and-variance-adjusted estimation (or "WLSMV"). In order to use this with the `lavaan` package, we need to Specify the variables as ordered factor and specify `estimator = "WLSMV"`.

```{r, echo=FALSE}
library(ltm)
data(Environment)
cat_dat <- Environment
head(cat_dat)

scale <- c("not very concerned", "slightly concerned", "very concerned")
cat_dat <- data.frame(lapply(cat_dat, ordered, levels = scale))
str(cat_dat)

assign("cat_dat", cat_dat, envir=globalenv())
``` 

Let’s say that the theory supports the practice of scoring the responses as reflections of a single latent variable. Mind you, this is simply for pedagogical purposes and not based on the original study (Brook et al., 1991) that the ltm package cites as the source of these data. Here is our model specification and fit:

```{r, cat, exercise=TRUE, echo=FALSE}
library(lavaan)
cfa_cat <- "F1 =~ LeadPetrol + RiverSea + RadioWaste + AirPollution + Chemicals + Nuclear"
cat_fit <- cfa(cfa_cat, 
               data= cat_dat, 
               estimator = "WLSMV",
               ordered = names(cat_dat), 
               mimic = "Mplus")

summary(cat_fit)
```
## 8. Factor Scores 

We can estimate the factor scores of each row in our data set using the `lavPredict()` function. Let's try this with the first model we created `cfa_fit1`

```{r, fscore, exercise=TRUE, echo=FALSE, exercise.setup='cfa1'}
f_scores <- lavPredict(cfa_fit1)
head(f_scores)
```


## 9. Internal Consistency reliability 
We can calculate coefficient omega of a factor, using its items’ pattern coefficients and error variances when we specify the latent variables as standardized, with this equation:
  
  $$ \omega = \frac{(\Sigma \hat{a}_{i})^2}{(\Sigma \hat{a}_{i})^2 + \Sigma \sigma_{u_i}^2} $$ 
  
- $a$: standardized factor loadings of each observed variable

- $\sigma^2$:  estimated error variances of each observed variable

```{r, echo=FALSE}
library(lavaan)

model <- "VISUAL =~ x1 + x2 + x3 
          TEXUAL =~ x4 + x5 + x6 
          SPEED  =~ x7 + x8 + x9
          "

cfa_fit1 <- cfa(model, 
                data = dat,
                estimator = "MLR", 
                mimic = "Mplus")

library(semPlot)

semPlot::semPaths(cfa_fit1, what = "est", intercept = FALSE,
                  rotation = 2, fade = F, edge.color = "black", 
                  curvePivot = T, sizeMan = 8, residuals = F, curvature = 2.5,
                  title = FALSE, sizeMan2 = 3, sizeLat2 = 8,
                  label.cex = 1, edge.label.cex = 1.2)

title("CFA Model 1", line = 1)
```


```{r, omega, exercise=TRUE, echo=FALSE}

omega <-"
         VISUAL =~ NA*x1 + L1*x1 + L2*x2 + L3*x3
      
      # Eror variance here 
         x1 ~~ E1*x1 
         x2 ~~ E2*x2
         x3 ~~ E3*x3 
      
      # Setting the factor variance to 1 
         VISUAL ~~ 1*VISUAL 
         
      # computing omega of the factor VISUAL 
         Omega := (L1+L2+L3)^2 / ((L1+L2+L3)^2 +(E1+E2+E3)) 
        "
omega_fit <- cfa(omega, 
                 data= dat, 
                 estimator="MLR", 
                 mimic ="Mplus")

summary(omega_fit)
```

#### Exercise 
Let's compute the omega score for the factor `TEXTUAL` and `SPEED`

```{r, your-code, exercise=TRUE, echo=FALSE, exercise.lines=20}

```

```{r, your-code2, exercise=TRUE, echo=FALSE, exercise.lines=20}

```

### Let's comapre 

```{r, omega-new, exercise=TRUE, echo=FALSE, exercise.setup="cfa1"}
library("semTools")
reliability(cfa_fit1)

``` 

